{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "FreqML2.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyM6+Yu2dFKXUWXrW0Pmc/yV",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/yuvalofek/FrequentistML/blob/master/FreqML2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "00LwS27I9boN",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "# **Frequentist ML Assignment 2 - Logistic Regression** \n",
        "Yuval Epstain Ofek\n",
        "---\n",
        "\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7YC5WxKV9nTh",
        "colab_type": "text"
      },
      "source": [
        "# **The provided Prompt:**\n",
        "\n",
        "1. Read sections: 4.1, 4.3 (not 4.3.1 and 4.3.2), 4.4-4.4.2  and the following paper:\n",
        "https://leon.bottou.org/publications/pdf/compstat-2010.pdf\n",
        "\n",
        "2. Grab a binary classification dataset from UCI or other repository. Divide your data into roughly 80% train, 10% validation, 10% test. \n",
        "3. Implement logistic regression with stochastic gradient descent as the optimization algorithm.\n",
        "4. Implement SGD without regularization and report your % correct on the test dataset.\n",
        "5. Implement SGD with regularization, select the best lambda parameter using the validation dataset, and report your % correct on the test dataset.\n",
        "6. Plot the likelihood function with respect to iterations for unregularized and regularized on one set of axes. Which one converges to a higher likelihood, and why?\n",
        "\n",
        "\n",
        "Optional, advanced things to try:\n",
        "\n",
        "- Implement SGD with the L-1 penalty and use it for feature selection (it is not that hard actually)\n",
        "- Compare SGD to Newton-Raphson by plotting the likelihood of both on one set of axes and explain why they are different."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JD6aM4iE9ak1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "46ddabd7-bad1-4019-b301-b001e48d8c83"
      },
      "source": [
        "#Getting a dataset\n",
        "!wget https://archive.ics.uci.edu/ml/machine-learning-databases/abalone/abalone.data"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-06-19 19:26:03--  https://archive.ics.uci.edu/ml/machine-learning-databases/abalone/abalone.data\n",
            "Resolving archive.ics.uci.edu (archive.ics.uci.edu)... 128.195.10.252\n",
            "Connecting to archive.ics.uci.edu (archive.ics.uci.edu)|128.195.10.252|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 191873 (187K) [application/x-httpd-php]\n",
            "Saving to: ‘abalone.data’\n",
            "\n",
            "abalone.data        100%[===================>] 187.38K   362KB/s    in 0.5s    \n",
            "\n",
            "2020-06-19 19:26:05 (362 KB/s) - ‘abalone.data’ saved [191873/191873]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3aKW05OmCEn5",
        "colab_type": "text"
      },
      "source": [
        "# Alabone Data Set\n",
        "[Link to Dataset Page](https://archive.ics.uci.edu/ml/datasets/Abalone)\n",
        "\n",
        "**Attribute Desctiption:**\n",
        "* Sex / nominal / -- / M, F, and I (infant)\n",
        "* Length / continuous / mm / Longest shell measurement\n",
        "* Diameter / continuous / mm / perpendicular to length\n",
        "* Height / continuous / mm / with meat in shell\n",
        "* Whole weight / continuous / grams / whole abalone\n",
        "* Shucked weight / continuous / grams / weight of meat\n",
        "* Viscera weight / continuous / grams / gut weight (after bleeding)\n",
        "* Shell weight / continuous / grams / after being dried\n",
        "* Rings / integer / -- / +1.5 gives the age in years\n",
        "\n",
        "Since the Sex is not binary I decided to omitt the infant. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CUgShSjaBwtT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TUOmCJrfB0xZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#copy of getdata from last assignment\n",
        "def getdata (name, cols= None, shuffle = True ):\n",
        "  # getdata (name, shuffle = True)\n",
        "  # function to read the csv into a numpy array and shuffle columns. \n",
        "  # Shuffles columns if shuffle is true and leaves them if false\n",
        "\n",
        "  # Loads the CSV data\n",
        "  data = pd.read_csv(name, header=None, usecols=cols)\n",
        "  #shuffling\n",
        "  if shuffle:\n",
        "    return data.sample(frac=1).reset_index(drop=True)\n",
        "  else:\n",
        "    return data"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ehhqhJjAFmyq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Extract from csv & shuffle\n",
        "dshuf = getdata('abalone.data')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BvE0i49YB7zx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 425
        },
        "outputId": "fe9ed43d-6d51-4427-acff-0a354c4a453d"
      },
      "source": [
        "#Clean out the infant label\n",
        "dshuf = dshuf[dshuf[0] != 'I']\n",
        "#Assign M = TRUE, and F = FALSE, and check\n",
        "print(dshuf[0])\n",
        "dshuf[0] = dshuf[0] == 'M'\n",
        "print(dshuf[0])"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0       M\n",
            "2       M\n",
            "3       M\n",
            "4       M\n",
            "5       M\n",
            "       ..\n",
            "4170    M\n",
            "4171    F\n",
            "4172    M\n",
            "4174    F\n",
            "4176    M\n",
            "Name: 0, Length: 2835, dtype: object\n",
            "0        True\n",
            "2        True\n",
            "3        True\n",
            "4        True\n",
            "5        True\n",
            "        ...  \n",
            "4170     True\n",
            "4171    False\n",
            "4172     True\n",
            "4174    False\n",
            "4176     True\n",
            "Name: 0, Length: 2835, dtype: bool\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "voNyGSf5FuJo",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "e109320a-b546-4bba-e2af-d7a1b18c6e85"
      },
      "source": [
        "### Spliting into Training, Validation, and Test\n",
        "\n",
        "#percentage of data for training is 80% and for testing is 10%\n",
        "perTrain = 0.80\n",
        "perTest = 0.10 \n",
        "len = dshuf.shape[0]\n",
        "\n",
        "#indices to split \n",
        "i_train =  round(len*perTrain)\n",
        "i_test = round(len*(perTest+perTrain))\n",
        "\n",
        "#actually splitting data\n",
        "tr_d  = dshuf[:i_train]\n",
        "val_d = dshuf[i_train:i_test]\n",
        "test_d = dshuf[i_test:]\n",
        "\n",
        "#display sizes of the split data to verify splitting was done correctly\n",
        "print('Training shape: ' + str(tr_d.shape), 'Validation shape: ' +str(val_d.shape),'Test shape: ' + str(test_d.shape))"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training shape: (2268, 9) Validation shape: (284, 9) Test shape: (283, 9)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oIq6ILfuF5YZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def logSGD (x,y):\n",
        "  "
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}